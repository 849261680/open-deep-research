from typing import Dict, List, Any, AsyncGenerator
from datetime import datetime
import json
import asyncio

from langchain.agents import AgentExecutor, create_react_agent
from langchain import hub
from langchain.memory import ConversationBufferMemory
from langchain.schema import BaseMessage, HumanMessage, AIMessage
from langchain.prompts import PromptTemplate
from langchain.callbacks.base import BaseCallbackHandler
from langchain.callbacks.manager import CallbackManager
from app.tools.search_tools import research_tools
from app.services.deepseek_service import deepseek_service
from app.services.search_tools import search_tools
from app.chains.research_chains import research_chains
from app.llms.deepseek_llm import DeepSeekLLM


class StreamingCallbackHandler(BaseCallbackHandler):
    """Callback handler for streaming responses."""
    
    def __init__(self, callback_func):
        self.callback_func = callback_func
    
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """Called when new token is generated."""
        if self.callback_func:
            self.callback_func(token)
    
    def on_agent_action(self, action, **kwargs) -> None:
        """Called when agent takes an action."""
        if self.callback_func:
            self.callback_func(f"ğŸ”§ ä½¿ç”¨å·¥å…·: {action.tool}")
    
    def on_agent_finish(self, finish, **kwargs) -> None:
        """Called when agent finishes."""
        if self.callback_func:
            self.callback_func("âœ… ä»£ç†æ‰§è¡Œå®Œæˆ")


class LangChainResearchAgent:
    """åŸºäºLangChainçš„ç ”ç©¶ä»£ç†"""
    
    def __init__(self):
        self.llm = None
        self.memory = None
        self.tools = research_tools
        self.agent_executor = None
        self.research_history = []
        self._initialized = False
    
    def _ensure_initialized(self):
        """æ‡’åŠ è½½åˆå§‹åŒ–"""
        if not self._initialized:
            try:
                print("æ­£åœ¨åˆå§‹åŒ–LLM...")
                self.llm = DeepSeekLLM()
                print("LLMåˆå§‹åŒ–å®Œæˆ")
                
                print("æ­£åœ¨åˆå§‹åŒ–Memory...")
                self.memory = ConversationBufferMemory(
                    memory_key="chat_history",
                    return_messages=True
                )
                print("Memoryåˆå§‹åŒ–å®Œæˆ")
                
                print("æ­£åœ¨åˆ›å»ºAgent...")
                self.agent_executor = self._create_agent()
                print("Agentåˆ›å»ºå®Œæˆ")
                
                self._initialized = True
                print("Agentå®Œå…¨åˆå§‹åŒ–å®Œæˆ")
            except Exception as e:
                print(f"Agent initialization error: {e}")
                import traceback
                traceback.print_exc()
                raise e
    
    def _create_agent(self) -> AgentExecutor:
        """åˆ›å»ºReActä»£ç†"""
        
        # ç›´æ¥ä½¿ç”¨ç®€å•çš„promptï¼Œé¿å…hub.pullé˜»å¡
        from langchain.prompts import PromptTemplate
        prompt = PromptTemplate.from_template(
            "Answer the following questions as best you can. You have access to the following tools:\n\n"
            "{tools}\n\n"
            "Use the following format:\n\n"
            "Question: the input question you must answer\n"
            "Thought: you should always think about what to do\n"
            "Action: the action to take, should be one of [{tool_names}]\n"
            "Action Input: the input to the action\n"
            "Observation: the result of the action\n"
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n"
            "Thought: I now know the final answer\n"
            "Final Answer: the final answer to the original input question\n\n"
            "Begin!\n\n"
            "Question: {input}\n"
            "Thought:{agent_scratchpad}"
        )
        
        # åˆ›å»ºReActä»£ç†
        agent = create_react_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt
        )
        
        # åˆ›å»ºä»£ç†æ‰§è¡Œå™¨
        agent_executor = AgentExecutor(
            agent=agent,
            tools=self.tools,
            memory=self.memory,
            verbose=True,
            handle_parsing_errors=True,
            max_iterations=10,
            early_stopping_method="generate"
        )
        
        return agent_executor
    
    def _format_tools(self) -> str:
        """æ ¼å¼åŒ–å·¥å…·æè¿°"""
        tool_descriptions = []
        for tool in self.tools:
            tool_descriptions.append(f"- {tool.name}: {tool.description}")
        return "\n".join(tool_descriptions)
    
    def _format_tool_names(self) -> str:
        """æ ¼å¼åŒ–å·¥å…·åç§°"""
        return ", ".join([tool.name for tool in self.tools])
    
    async def plan_research(self, query: str) -> List[Dict[str, Any]]:
        """ä½¿ç”¨é“¾åˆ¶å®šç ”ç©¶è®¡åˆ’"""
        self._ensure_initialized()
        try:
            planning_chain = research_chains.create_planning_chain()
            result = await planning_chain.ainvoke({"query": query})
            response = result.get("research_plan", result) if isinstance(result, dict) else result
            
            # è§£æJSONå“åº”
            if "```json" in str(response):
                json_str = response.split("```json")[1].split("```")[0].strip()
            else:
                json_str = response
            
            plan_data = json.loads(json_str)
            return plan_data.get("research_plan", [])
        except Exception as e:
            print(f"Research planning error: {e}")
            # è¿”å›é»˜è®¤è®¡åˆ’
            return [
                {
                    "step": 1,
                    "title": "èƒŒæ™¯è°ƒç ”",
                    "description": "ä½¿ç”¨ç»¼åˆæœç´¢æ”¶é›†åŸºæœ¬ä¿¡æ¯",
                    "tool": "comprehensive_search",
                    "search_queries": [query, f"{query} èƒŒæ™¯"],
                    "expected_outcome": "äº†è§£åŸºæœ¬æ¦‚å¿µå’ŒèƒŒæ™¯"
                },
                {
                    "step": 2,
                    "title": "æ·±å…¥åˆ†æ", 
                    "description": "ä½¿ç”¨Googleæœç´¢è·å–æœ€æ–°ä¿¡æ¯",
                    "tool": "google_search",
                    "search_queries": [f"{query} åˆ†æ", f"{query} æœ€æ–°"],
                    "expected_outcome": "è·å¾—è¯¦ç»†åˆ†æå’Œå½“å‰çŠ¶å†µ"
                },
                {
                    "step": 3,
                    "title": "æƒå¨èµ„æ–™",
                    "description": "ä½¿ç”¨Wikipediaæœç´¢è·å–æƒå¨ä¿¡æ¯", 
                    "tool": "wikipedia_search",
                    "search_queries": [query, f"{query} å®šä¹‰"],
                    "expected_outcome": "è·å¾—å¯é çš„å‚è€ƒèµ„æ–™"
                }
            ]
    
    async def execute_research_step(self, step: Dict[str, Any], query: str) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªç ”ç©¶æ­¥éª¤"""
        step_result = {
            "step": step["step"],
            "title": step["title"],
            "status": "executing",
            "search_results": {},
            "analysis": "",
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            # 1. æ‰§è¡Œæœç´¢
            search_results = {}
            if step.get("search_queries"):
                for search_query in step["search_queries"]:
                    if step.get("tool") == "comprehensive_search":
                        search_result = await search_tools.comprehensive_search(search_query)
                    elif step.get("tool") == "google_search":
                        search_result = {"web": await search_tools.google_search(search_query)}
                    elif step.get("tool") == "wikipedia_search":
                        search_result = {"wikipedia": await search_tools.wikipedia_search(search_query)}
                    else:
                        search_result = await search_tools.comprehensive_search(search_query)
                    
                    search_results[search_query] = search_result
            
            step_result["search_results"] = search_results
            
            # 2. ä½¿ç”¨é“¾åˆ†ææœç´¢ç»“æœ
            if search_results:
                # åˆå¹¶æ‰€æœ‰æœç´¢ç»“æœ
                combined_results = {}
                for query_results in search_results.values():
                    for source, items in query_results.items():
                        if source not in combined_results:
                            combined_results[source] = []
                        combined_results[source].extend(items)
                
                # ä½¿ç”¨é“¾è¿›è¡Œåˆ†æ
                analysis = await research_chains.analyze_search_results_with_chain(
                    step["title"], 
                    combined_results
                )
                step_result["analysis"] = analysis
            else:
                step_result["analysis"] = "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœ"
            
            step_result["status"] = "completed"
        except Exception as e:
            step_result["analysis"] = f"æ‰§è¡Œé”™è¯¯: {str(e)}"
            step_result["status"] = "failed"
        
        return step_result
    
    async def generate_final_report(self, research_results: List[Dict[str, Any]], original_query: str) -> str:
        """ä½¿ç”¨é“¾ç”Ÿæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Š"""
        
        try:
            # 1. æ”¶é›†æ‰€æœ‰åˆ†æç»“æœ
            step_analyses = []
            for result in research_results:
                if result["status"] == "completed":
                    step_analyses.append({
                        "title": result["title"],
                        "analysis": result["analysis"]
                    })
            
            # 2. ä½¿ç”¨ç»¼åˆåˆ†æé“¾
            synthesis_chain = research_chains.create_synthesis_chain()
            all_analyses_text = "\n\n".join([f"**{analysis['title']}**:\n{analysis['analysis']}" for analysis in step_analyses])
            
            result = await synthesis_chain.ainvoke({
                "query": original_query,
                "all_analyses": all_analyses_text
            })
            synthesis = result.get("synthesis", result) if isinstance(result, dict) else result
            
            # 3. ä½¿ç”¨æŠ¥å‘Šç”Ÿæˆé“¾
            report_chain = research_chains.create_report_generation_chain()
            
            result = await report_chain.ainvoke({
                "query": original_query,
                "research_plan": json.dumps([{"title": r["title"], "description": r.get("description", "")} for r in research_results], ensure_ascii=False),
                "step_analyses": all_analyses_text,
                "synthesis": synthesis
            })
            final_report = result.get("final_report", result) if isinstance(result, dict) else result
            
            return final_report
            
        except Exception as e:
            # å›é€€åˆ°ç®€å•æŠ¥å‘Šç”Ÿæˆ
            all_findings = []
            for result in research_results:
                if result["status"] == "completed":
                    all_findings.append(f"**{result['title']}**: {result['analysis']}")
            
            findings_text = "\n\n".join(all_findings)
            
            simple_report = f"""
# {original_query} - ç ”ç©¶æŠ¥å‘Š

## ä¸»è¦å‘ç°

{findings_text}

## ç»“è®º

åŸºäºä»¥ä¸Šç ”ç©¶ï¼Œæˆ‘ä»¬å¯¹"{original_query}"è¿›è¡Œäº†å¤šæ–¹é¢çš„åˆ†æå’Œè°ƒç ”ã€‚

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
            return simple_report
    
    async def conduct_research(self, query: str) -> AsyncGenerator[Dict[str, Any], None]:
        """æ‰§è¡Œå®Œæ•´çš„ç ”ç©¶æµç¨‹"""
        self._ensure_initialized()
        
        # 1. åˆ¶å®šç ”ç©¶è®¡åˆ’
        yield {"type": "planning", "message": "æ­£åœ¨åˆ¶å®šç ”ç©¶è®¡åˆ’...", "data": None}
        
        research_plan = await self.plan_research(query)
        yield {"type": "plan", "message": "ç ”ç©¶è®¡åˆ’åˆ¶å®šå®Œæˆ", "data": research_plan}
        
        # 2. æ‰§è¡Œç ”ç©¶æ­¥éª¤
        research_results = []
        for step in research_plan:
            yield {"type": "step_start", "message": f"å¼€å§‹æ‰§è¡Œï¼š{step['title']}", "data": step}
            
            step_result = await self.execute_research_step(step, query)
            research_results.append(step_result)
            
            yield {"type": "step_complete", "message": f"å®Œæˆï¼š{step['title']}", "data": step_result}
        
        # 3. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        yield {"type": "report_generating", "message": "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Š...", "data": None}
        
        final_report = await self.generate_final_report(research_results, query)
        
        # ä¿å­˜åˆ°å†å²è®°å½•
        research_record = {
            "query": query,
            "plan": research_plan,
            "results": research_results,
            "report": final_report,
            "timestamp": datetime.now().isoformat()
        }
        self.research_history.append(research_record)
        
        yield {"type": "report_complete", "message": "ç ”ç©¶å®Œæˆ", "data": research_record}
    
    def get_research_history(self) -> List[Dict[str, Any]]:
        """è·å–ç ”ç©¶å†å²"""
        return self.research_history
    
    def clear_memory(self):
        """æ¸…ç©ºè®°å¿†"""
        if self.memory:
            self.memory.clear()
        self.research_history = []


# å…¨å±€å®ä¾‹
langchain_research_agent = LangChainResearchAgent()