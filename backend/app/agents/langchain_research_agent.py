from typing import Dict, List, Any, AsyncGenerator
from datetime import datetime
import json
import asyncio

from langchain.agents import AgentExecutor, create_react_agent
from langchain import hub
from langchain.memory import ConversationBufferMemory
from langchain.schema import BaseMessage, HumanMessage, AIMessage
from langchain.prompts import PromptTemplate
from langchain.callbacks.base import BaseCallbackHandler
from langchain.callbacks.manager import CallbackManager
from app.tools.search_tools import research_tools
from app.services.deepseek_service import deepseek_service
from app.services.search_tools import search_tools
from app.chains.research_chains import research_chains
from app.llms.deepseek_llm import DeepSeekLLM


class StreamingCallbackHandler(BaseCallbackHandler):
    """Callback handler for streaming responses."""
    
    def __init__(self, callback_func):
        self.callback_func = callback_func
    
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """Called when new token is generated."""
        if self.callback_func:
            self.callback_func(token)
    
    def on_agent_action(self, action, **kwargs) -> None:
        """Called when agent takes an action."""
        if self.callback_func:
            self.callback_func(f"ğŸ”§ ä½¿ç”¨å·¥å…·: {action.tool}")
    
    def on_agent_finish(self, finish, **kwargs) -> None:
        """Called when agent finishes."""
        if self.callback_func:
            self.callback_func("âœ… ä»£ç†æ‰§è¡Œå®Œæˆ")


class LangChainResearchAgent:
    """åŸºäºLangChainçš„ç ”ç©¶ä»£ç†"""
    
    def __init__(self):
        self.llm = None
        self.memory = None
        self.tools = research_tools
        self.agent_executor = None
        self.research_history = []
        self._initialized = False
    
    def _ensure_initialized(self):
        """æ‡’åŠ è½½åˆå§‹åŒ–"""
        if not self._initialized:
            try:
                print("æ­£åœ¨åˆå§‹åŒ–LLM...")
                self.llm = DeepSeekLLM()
                print("LLMåˆå§‹åŒ–å®Œæˆ")
                
                print("æ­£åœ¨åˆå§‹åŒ–Memory...")
                self.memory = ConversationBufferMemory(
                    memory_key="chat_history",
                    return_messages=True
                )
                print("Memoryåˆå§‹åŒ–å®Œæˆ")
                
                print("æ­£åœ¨åˆ›å»ºAgent...")
                self.agent_executor = self._create_agent()
                print("Agentåˆ›å»ºå®Œæˆ")
                
                self._initialized = True
                print("Agentå®Œå…¨åˆå§‹åŒ–å®Œæˆ")
            except Exception as e:
                print(f"Agent initialization error: {e}")
                import traceback
                traceback.print_exc()
                raise e
    
    def _create_agent(self) -> AgentExecutor:
        """åˆ›å»ºReActä»£ç†"""
        
        # ç›´æ¥ä½¿ç”¨ç®€å•çš„promptï¼Œé¿å…hub.pullé˜»å¡
        from langchain.prompts import PromptTemplate
        prompt = PromptTemplate.from_template(
            "Answer the following questions as best you can. You have access to the following tools:\n\n"
            "{tools}\n\n"
            "Use the following format:\n\n"
            "Question: the input question you must answer\n"
            "Thought: you should always think about what to do\n"
            "Action: the action to take, should be one of [{tool_names}]\n"
            "Action Input: the input to the action\n"
            "Observation: the result of the action\n"
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n"
            "Thought: I now know the final answer\n"
            "Final Answer: the final answer to the original input question\n\n"
            "Begin!\n\n"
            "Question: {input}\n"
            "Thought:{agent_scratchpad}"
        )
        
        # åˆ›å»ºReActä»£ç†
        agent = create_react_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt
        )
        
        # åˆ›å»ºä»£ç†æ‰§è¡Œå™¨
        agent_executor = AgentExecutor(
            agent=agent,
            tools=self.tools,
            memory=self.memory,
            verbose=True,
            handle_parsing_errors=True,
            max_iterations=10,
            early_stopping_method="generate"
        )
        
        return agent_executor
    
    def _format_tools(self) -> str:
        """æ ¼å¼åŒ–å·¥å…·æè¿°"""
        tool_descriptions = []
        for tool in self.tools:
            tool_descriptions.append(f"- {tool.name}: {tool.description}")
        return "\n".join(tool_descriptions)
    
    def _format_tool_names(self) -> str:
        """æ ¼å¼åŒ–å·¥å…·åç§°"""
        return ", ".join([tool.name for tool in self.tools])
    
    async def plan_research(self, query: str, callback=None) -> List[Dict[str, Any]]:
        """ä½¿ç”¨é“¾åˆ¶å®šç ”ç©¶è®¡åˆ’ï¼Œæ”¯æŒè¿›åº¦å›è°ƒ"""
        self._ensure_initialized()
        
        if callback:
            await callback({"type": "planning_step", "message": "ğŸ” åˆ†æç ”ç©¶ä¸»é¢˜...", "data": {"step": "analyzing_topic"}})
        
        try:
            if callback:
                await callback({"type": "planning_step", "message": "ğŸ§  è°ƒç”¨AIç”Ÿæˆç ”ç©¶è®¡åˆ’...", "data": {"step": "calling_ai"}})
            
            planning_chain = research_chains.create_planning_chain()
            result = await planning_chain.ainvoke({"query": query})
            response = result.get("research_plan", result) if isinstance(result, dict) else result
            
            if callback:
                await callback({"type": "planning_step", "message": "ğŸ“‹ è§£æç ”ç©¶è®¡åˆ’ç»“æ„...", "data": {"step": "parsing_plan"}})
            
            # è§£æJSONå“åº”
            if "```json" in str(response):
                json_str = response.split("```json")[1].split("```")[0].strip()
            else:
                json_str = response
            
            plan_data = json.loads(json_str)
            plan = plan_data.get("research_plan", [])
            
            if callback:
                await callback({"type": "planning_step", "message": f"âœ… æˆåŠŸç”Ÿæˆ{len(plan)}ä¸ªç ”ç©¶æ­¥éª¤", "data": {"step": "plan_ready", "plan_preview": plan}})
            
            return plan
        except Exception as e:
            print(f"Research planning error: {e}")
            
            if callback:
                await callback({"type": "planning_step", "message": "âš ï¸ AIè®¡åˆ’ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è®¡åˆ’", "data": {"step": "fallback_plan"}})
            
            # è¿”å›é»˜è®¤è®¡åˆ’
            default_plan = [
                {
                    "step": 1,
                    "title": "èƒŒæ™¯è°ƒç ”",
                    "description": "ä½¿ç”¨ç»¼åˆæœç´¢æ”¶é›†åŸºæœ¬ä¿¡æ¯",
                    "tool": "comprehensive_search",
                    "search_queries": [query, f"{query} èƒŒæ™¯"],
                    "expected_outcome": "äº†è§£åŸºæœ¬æ¦‚å¿µå’ŒèƒŒæ™¯"
                },
                {
                    "step": 2,
                    "title": "æ·±å…¥åˆ†æ", 
                    "description": "ä½¿ç”¨Tavilyæœç´¢è·å–æœ€æ–°ä¿¡æ¯",
                    "tool": "comprehensive_search",
                    "search_queries": [f"{query} åˆ†æ", f"{query} æœ€æ–°"],
                    "expected_outcome": "è·å¾—è¯¦ç»†åˆ†æå’Œå½“å‰çŠ¶å†µ"
                },
                {
                    "step": 3,
                    "title": "ç»¼åˆè¯„ä¼°",
                    "description": "å…¨é¢æœç´¢ç›¸å…³èµ„æ–™è¿›è¡Œç»¼åˆåˆ†æ", 
                    "tool": "comprehensive_search",
                    "search_queries": [f"{query} è¯„ä¼°", f"{query} æ€»ç»“"],
                    "expected_outcome": "è·å¾—å…¨é¢çš„åˆ†æç»“è®º"
                }
            ]
            
            if callback:
                await callback({"type": "planning_step", "message": "ğŸ“‹ é»˜è®¤è®¡åˆ’å‡†å¤‡å®Œæˆ", "data": {"step": "default_ready", "plan_preview": default_plan}})
            
            return default_plan
    
    async def _plan_research_with_updates(self, query: str) -> AsyncGenerator[Dict[str, Any], None]:
        """å¸¦è¿›åº¦æ›´æ–°çš„ç ”ç©¶è®¡åˆ’åˆ¶å®š"""
        
        try:
            # ç›´æ¥è°ƒç”¨AIç”Ÿæˆè®¡åˆ’ï¼Œä¸æ˜¾ç¤ºä¸­é—´æ­¥éª¤
            planning_chain = research_chains.create_planning_chain()
            result = await planning_chain.ainvoke({"query": query})
            response = result.get("research_plan", result) if isinstance(result, dict) else result
            
            # è§£æJSONå“åº”
            if "```json" in str(response):
                json_str = response.split("```json")[1].split("```")[0].strip()
            else:
                json_str = response
            
            plan_data = json.loads(json_str)
            plan = plan_data.get("research_plan", [])
            
            # ç›´æ¥å‘é€å®Œæ•´è®¡åˆ’
            yield {"type": "plan", "message": "ç ”ç©¶è®¡åˆ’åˆ¶å®šå®Œæˆ", "data": plan}
            
        except Exception as e:
            print(f"Research planning error: {e}")
            
            # AIç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è®¡åˆ’
            default_plan = [
                {
                    "step": 1,
                    "title": "èƒŒæ™¯è°ƒç ”",
                    "description": "ä½¿ç”¨ç»¼åˆæœç´¢æ”¶é›†åŸºæœ¬ä¿¡æ¯",
                    "tool": "comprehensive_search",
                    "search_queries": [query, f"{query} èƒŒæ™¯"],
                    "expected_outcome": "äº†è§£åŸºæœ¬æ¦‚å¿µå’ŒèƒŒæ™¯"
                },
                {
                    "step": 2,
                    "title": "æ·±å…¥åˆ†æ", 
                    "description": "ä½¿ç”¨Tavilyæœç´¢è·å–æœ€æ–°ä¿¡æ¯",
                    "tool": "comprehensive_search",
                    "search_queries": [f"{query} åˆ†æ", f"{query} æœ€æ–°"],
                    "expected_outcome": "è·å¾—è¯¦ç»†åˆ†æå’Œå½“å‰çŠ¶å†µ"
                },
                {
                    "step": 3,
                    "title": "ç»¼åˆè¯„ä¼°",
                    "description": "å…¨é¢æœç´¢ç›¸å…³èµ„æ–™è¿›è¡Œç»¼åˆåˆ†æ", 
                    "tool": "comprehensive_search",
                    "search_queries": [f"{query} è¯„ä¼°", f"{query} æ€»ç»“"],
                    "expected_outcome": "è·å¾—å…¨é¢çš„åˆ†æç»“è®º"
                }
            ]
            
            yield {"type": "plan", "message": "ç ”ç©¶è®¡åˆ’åˆ¶å®šå®Œæˆ", "data": default_plan}
    
    async def _execute_research_step_with_updates(self, step: Dict[str, Any], query: str) -> AsyncGenerator[Dict[str, Any], None]:
        """å¸¦è¿›åº¦æ›´æ–°çš„ç ”ç©¶æ­¥éª¤æ‰§è¡Œ"""
        step_result = {
            "step": step["step"],
            "title": step["title"],
            "status": "executing",
            "search_results": {},
            "search_sources": [],  # æ–°å¢ï¼šæœç´¢æ¥æºä¿¡æ¯
            "analysis": "",
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            # 1. æ‰§è¡Œæœç´¢ - æ˜¾ç¤ºæœç´¢è¿›åº¦
            search_results = {}
            all_search_sources = []
            
            if step.get("search_queries"):
                for i, search_query in enumerate(step["search_queries"]):
                    yield {"type": "search_progress", "message": f"æ­£åœ¨æœç´¢ï¼š{search_query}", "data": {"query": search_query, "step": i+1, "total": len(step["search_queries"])}}
                    
                    if step.get("tool") == "comprehensive_search":
                        search_result = await search_tools.comprehensive_search(search_query)
                    elif step.get("tool") == "google_search":
                        search_result = {"web": await search_tools.google_search(search_query)}
                    elif step.get("tool") == "wikipedia_search":
                        search_result = {"wikipedia": await search_tools.wikipedia_search(search_query)}
                    else:
                        search_result = await search_tools.comprehensive_search(search_query)
                    
                    search_results[search_query] = search_result
                    
                    # æ”¶é›†æœç´¢æ¥æºä¿¡æ¯
                    for source_type, items in search_result.items():
                        for item in items[:3]:  # åªå–å‰3ä¸ªç»“æœ
                            if 'title' in item and 'link' in item:
                                all_search_sources.append({
                                    "title": item['title'],
                                    "link": item['link'],
                                    "source": source_type,
                                    "query": search_query
                                })
                    
                    yield {"type": "search_result", "message": f"æ‰¾åˆ° {sum(len(items) for items in search_result.values())} ä¸ªç»“æœ", "data": {"query": search_query, "sources": [{"title": item['title'], "link": item['link'], "source": source_type} for source_type, items in search_result.items() for item in items[:3] if 'title' in item and 'link' in item]}}
            
            step_result["search_results"] = search_results
            step_result["search_sources"] = all_search_sources
            
            # 2. åˆ†ææœç´¢ç»“æœ
            yield {"type": "analysis_progress", "message": "æ­£åœ¨åˆ†ææœç´¢ç»“æœ...", "data": None}
            
            if search_results:
                # åˆå¹¶æ‰€æœ‰æœç´¢ç»“æœ
                combined_results = {}
                for query_results in search_results.values():
                    for source, items in query_results.items():
                        if source not in combined_results:
                            combined_results[source] = []
                        combined_results[source].extend(items)
                
                # ä½¿ç”¨é“¾è¿›è¡Œåˆ†æ
                analysis = await research_chains.analyze_search_results_with_chain(
                    step["title"], 
                    combined_results
                )
                step_result["analysis"] = analysis
            else:
                step_result["analysis"] = "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœ"
            
            step_result["status"] = "completed"
            yield {"type": "step_complete", "message": f"å®Œæˆï¼š{step['title']}", "data": step_result}
            
        except Exception as e:
            step_result["analysis"] = f"æ‰§è¡Œé”™è¯¯: {str(e)}"
            step_result["status"] = "failed"
            yield {"type": "step_complete", "message": f"æ­¥éª¤å¤±è´¥ï¼š{step['title']}", "data": step_result}
    
    async def execute_research_step(self, step: Dict[str, Any], query: str) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªç ”ç©¶æ­¥éª¤"""
        step_result = {
            "step": step["step"],
            "title": step["title"],
            "status": "executing",
            "search_results": {},
            "analysis": "",
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            # 1. æ‰§è¡Œæœç´¢
            search_results = {}
            if step.get("search_queries"):
                for search_query in step["search_queries"]:
                    if step.get("tool") == "comprehensive_search":
                        search_result = await search_tools.comprehensive_search(search_query)
                    elif step.get("tool") == "google_search":
                        search_result = {"web": await search_tools.google_search(search_query)}
                    elif step.get("tool") == "wikipedia_search":
                        search_result = {"wikipedia": await search_tools.wikipedia_search(search_query)}
                    else:
                        search_result = await search_tools.comprehensive_search(search_query)
                    
                    search_results[search_query] = search_result
            
            step_result["search_results"] = search_results
            
            # 2. ä½¿ç”¨é“¾åˆ†ææœç´¢ç»“æœ
            if search_results:
                # åˆå¹¶æ‰€æœ‰æœç´¢ç»“æœ
                combined_results = {}
                for query_results in search_results.values():
                    for source, items in query_results.items():
                        if source not in combined_results:
                            combined_results[source] = []
                        combined_results[source].extend(items)
                
                # ä½¿ç”¨é“¾è¿›è¡Œåˆ†æ
                analysis = await research_chains.analyze_search_results_with_chain(
                    step["title"], 
                    combined_results
                )
                step_result["analysis"] = analysis
            else:
                step_result["analysis"] = "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœ"
            
            step_result["status"] = "completed"
        except Exception as e:
            step_result["analysis"] = f"æ‰§è¡Œé”™è¯¯: {str(e)}"
            step_result["status"] = "failed"
        
        return step_result
    
    async def generate_final_report(self, research_results: List[Dict[str, Any]], original_query: str) -> str:
        """ç”Ÿæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Šï¼Œä¼˜åŒ–ä¸ºå•æ¬¡APIè°ƒç”¨"""
        
        try:
            # 1. æ”¶é›†æ‰€æœ‰åˆ†æç»“æœ
            step_analyses = []
            for result in research_results:
                if result["status"] == "completed":
                    step_analyses.append({
                        "title": result["title"],
                        "analysis": result["analysis"]
                    })
            
            # 2. ç›´æ¥ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šï¼Œé¿å…å¤šæ¬¡APIè°ƒç”¨
            all_analyses_text = "\n\n".join([f"**{analysis['title']}**:\n{analysis['analysis']}" for analysis in step_analyses])
            
            # é™åˆ¶è¾“å…¥é•¿åº¦ï¼Œç¡®ä¿ä¸è¶…æ—¶
            max_input_length = 1500
            if len(all_analyses_text) > max_input_length:
                all_analyses_text = all_analyses_text[:max_input_length] + "...\n\n[å†…å®¹å·²æˆªæ–­]"
                print(f"âš ï¸ ç ”ç©¶ç»“æœè¿‡é•¿ï¼Œå·²æˆªæ–­è‡³ {max_input_length} å­—ç¬¦")
            
            # åˆ›å»ºç®€åŒ–çš„æŠ¥å‘Šç”Ÿæˆæç¤º
            print(f"ğŸ“Š æœ€ç»ˆæŠ¥å‘Šè¾“å…¥ç»Ÿè®¡:")
            print(f"   - æŸ¥è¯¢: {original_query}")
            print(f"   - åˆ†ææ–‡æœ¬é•¿åº¦: {len(all_analyses_text)} å­—ç¬¦")
            print(f"   - å®Œæˆçš„æ­¥éª¤æ•°: {len(step_analyses)}")
            
            report_prompt = f"""
è¯·åŸºäºä»¥ä¸‹ç ”ç©¶ç»“æœï¼Œä¸º"{original_query}"ç”Ÿæˆä¸€ä»½ç®€æ´çš„ç ”ç©¶æŠ¥å‘Šï¼š

ç ”ç©¶ç»“æœï¼š
{all_analyses_text}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼ç”ŸæˆæŠ¥å‘Šï¼š

# {original_query} - ç ”ç©¶æŠ¥å‘Š

## æ ¸å¿ƒå‘ç°
ï¼ˆåˆ—å‡º3-5ä¸ªå…³é”®å‘ç°ï¼‰

## è¯¦ç»†åˆ†æ  
ï¼ˆåŸºäºç ”ç©¶ç»“æœçš„æ·±å…¥åˆ†æï¼‰

## ç»“è®ºä¸å»ºè®®
ï¼ˆæ€»ç»“æ€§ç»“è®ºå’Œå®ç”¨å»ºè®®ï¼‰

è¦æ±‚ï¼š
1. å†…å®¹ç®€æ´ä½†æœ‰æ·±åº¦
2. çªå‡ºé‡ç‚¹ä¿¡æ¯
3. é€»è¾‘æ¸…æ™°
4. ä¸­æ–‡æ’°å†™
"""
            
            # ç›´æ¥è°ƒç”¨LLMï¼Œé¿å…å¤æ‚é“¾å¼å¤„ç†
            from app.services.deepseek_service import deepseek_service
            final_report = await deepseek_service.generate_response(report_prompt, max_tokens=1500)
            
            return final_report
            
        except Exception as e:
            # å›é€€åˆ°ç®€å•æŠ¥å‘Šç”Ÿæˆ
            all_findings = []
            for result in research_results:
                if result["status"] == "completed":
                    all_findings.append(f"**{result['title']}**: {result['analysis']}")
            
            findings_text = "\n\n".join(all_findings)
            
            simple_report = f"""
# {original_query} - ç ”ç©¶æŠ¥å‘Š

## ä¸»è¦å‘ç°

{findings_text}

## ç»“è®º

åŸºäºä»¥ä¸Šç ”ç©¶ï¼Œæˆ‘ä»¬å¯¹"{original_query}"è¿›è¡Œäº†å¤šæ–¹é¢çš„åˆ†æå’Œè°ƒç ”ã€‚

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
            return simple_report
    
    async def conduct_research(self, query: str) -> AsyncGenerator[Dict[str, Any], None]:
        """æ‰§è¡Œå®Œæ•´çš„ç ”ç©¶æµç¨‹"""
        self._ensure_initialized()
        
        # 1. åˆ¶å®šç ”ç©¶è®¡åˆ’ - æ˜¾ç¤ºè¯¦ç»†è¿‡ç¨‹
        yield {"type": "planning", "message": "æ­£åœ¨åˆ¶å®šç ”ç©¶è®¡åˆ’...", "data": None}
        
        # å®šä¹‰å›è°ƒå‡½æ•°æ¥å®æ—¶å‘é€è®¡åˆ’åˆ¶å®šè¿›åº¦
        async def planning_callback(update):
            yield update
        
        # ä½¿ç”¨ç”Ÿæˆå™¨æ¥æ•è·è®¡åˆ’åˆ¶å®šçš„è¿›åº¦
        planning_updates = []
        
        async def capture_planning_updates(update):
            planning_updates.append(update)
            yield update
        
        # è°ƒç”¨å¸¦å›è°ƒçš„è®¡åˆ’åˆ¶å®šæ–¹æ³•
        research_plan = None
        async for update in self._plan_research_with_updates(query):
            yield update
            if update.get("type") == "plan" and update.get("data"):
                research_plan = update["data"]
        
        if not research_plan:
            # å¦‚æœæ²¡æœ‰è·å¾—è®¡åˆ’ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
            research_plan = await self.plan_research(query)
            yield {"type": "plan", "message": "ç ”ç©¶è®¡åˆ’åˆ¶å®šå®Œæˆ", "data": research_plan}
        
        # 2. æ‰§è¡Œç ”ç©¶æ­¥éª¤
        research_results = []
        for step in research_plan:
            yield {"type": "step_start", "message": f"å¼€å§‹æ‰§è¡Œï¼š{step['title']}", "data": step}
            
            # æ‰§è¡Œå¸¦è¿›åº¦æ›´æ–°çš„ç ”ç©¶æ­¥éª¤
            step_result = None
            async for update in self._execute_research_step_with_updates(step, query):
                yield update
                if update.get("type") == "step_complete":
                    step_result = update["data"]
                    research_results.append(step_result)
        
        # 3. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        yield {"type": "report_generating", "message": "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Š...", "data": None}
        
        final_report = await self.generate_final_report(research_results, query)
        
        # ä¿å­˜åˆ°å†å²è®°å½•
        research_record = {
            "query": query,
            "plan": research_plan,
            "results": research_results,
            "report": final_report,
            "timestamp": datetime.now().isoformat()
        }
        self.research_history.append(research_record)
        
        yield {"type": "report_complete", "message": "ç ”ç©¶å®Œæˆ", "data": research_record}
    
    def get_research_history(self) -> List[Dict[str, Any]]:
        """è·å–ç ”ç©¶å†å²"""
        return self.research_history
    
    def clear_memory(self):
        """æ¸…ç©ºè®°å¿†"""
        if self.memory:
            self.memory.clear()
        self.research_history = []


# å…¨å±€å®ä¾‹
langchain_research_agent = LangChainResearchAgent()